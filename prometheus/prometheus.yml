global:
  scrape_interval: 15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  # external_labels:
  #   monitor: "codelab-monitor"

# A scrape configuration containing two endpoints to scrape: Prometheus itself, and the push gateway
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  # This job tries to scrape data from the host machine on port 8080. This way
  # not everything needs to be run inside the docker-compose set up
  - job_name: "host-machine"
    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
      # NOTE - We use the project name from docker compose as well as the *container* port for the push gateway
      - targets: ["host.docker.internal:8080"]

  - job_name: "prometheus-push-gateway"
    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
      # NOTE - We use the project name from docker compose as well as the *container* port for the push gateway
      - targets: ["prometheus-push-gateway:80"]

  # NOTE - If you're running the Slack app locally, it should generate metrics that you can also inspect
  - job_name: "slack-app"
    scrape_interval: 5s
    static_configs:
      - targets: ["host.docker.internal:3031"]

rule_files:
  - "/etc/prometheus/autometrics.rules.yml"

alerting:
  alertmanagers:
    - scheme: http
      static_configs:
        - targets: [ 'alertmanager:9093' ]
